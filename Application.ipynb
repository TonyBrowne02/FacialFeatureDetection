{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2463f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "import easygui as eg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7c5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_file_explore():\n",
    "    # Prompt user to select an image file\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select an Image File\",\n",
    "        filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")]\n",
    "    )\n",
    "    if not file_path:\n",
    "        eg.msgbox(\"No File Selected.\", \"Error\")\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d85f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reizing image\n",
    "def resize(img, height=640):\n",
    "    img_X_scale = height / img.shape[0]\n",
    "    new_img_width = int(img.shape[1] * img_X_scale)\n",
    "    img_resized = cv2.resize(img, (int(new_img_width), int(height)))\n",
    "    return img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6964a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiLateralFitlerDenoise(img, diameter = 9, sigma_color=75, sigma_space=75 ):\n",
    "    return cv2.bilateralFilter(img, diameter, sigma_color, sigma_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41231fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grayscale(image):\n",
    "    if len(image.shape) == 2:\n",
    "        return True\n",
    "    if image.shape[2] == 1:#no of colour channels \n",
    "        return True\n",
    "    \n",
    "    channels = cv2.split(image)\n",
    "    return np.allclose(channels[0], channels[1]) and np.allclose(channels[0], channels[2]) # checks if the values are close "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4786e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsharpMask(img, kernel_size=5, sigma=1.5, amount =1.0, threshold=0):\n",
    "    blurred = cv2.GaussianBlur(img, (kernel_size, kernel_size), sigma, sigma)\n",
    "\n",
    "    sharpened = cv2.addWeighted(img, 1 + amount, blurred, -amount, 0)\n",
    "\n",
    "    # Apply a threshold to the sharpening\n",
    "    image_sharp = np.where((img - blurred) < -threshold, 0, sharpened)\n",
    "\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe67c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanceContrast(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    if (is_grayscale(img)):#check if gray\n",
    "        \n",
    "        enhanced = clahe.apply(img)\n",
    "        return enhanced\n",
    "    else:\n",
    "        # Convert to LAB color space\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        # Apply CLAHE to L channel\n",
    "        enhanced_l = clahe.apply(l)\n",
    "        \n",
    "        # Merge and convert back\n",
    "        enhanced_lab = cv2.merge([enhanced_l, a, b])\n",
    "        return cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a277d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_file_explore():\n",
    "    # Prompt user to select a video file\n",
    "    file_path = filedialog.askopenfilename(\n",
    "        title=\"Select a Video File\",\n",
    "        filetypes=[(\"Video files\", \"*.mp4 *.avi *.mov\")]\n",
    "    )\n",
    "    if not file_path:\n",
    "        eg.msgbox(\"No File Selected.\", \"Error\")\n",
    "        return None\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d1dce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_image():\n",
    "    image = cv2.VideoCapture(0)\n",
    "    (check, image) = image.read()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53df0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_with_skin_mask(frame):\n",
    "    # Convert to YCrCb color space to detect skin color\n",
    "    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    # Define skin color range in YCrCb\n",
    "    lower = np.array([0, 133, 77], dtype=np.uint8)\n",
    "    upper = np.array([255, 173, 127], dtype=np.uint8)\n",
    "    # Create a mask for skin-colored regions\n",
    "    skin_mask = cv2.inRange(ycrcb, lower, upper)\n",
    "    return skin_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "700d0863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_with_skin_region(frame):\n",
    "    # Generate a mask for the skin-colored region\n",
    "    skin_mask = detect_faces_with_skin_mask(frame)\n",
    "    # Extract the skin region from the original image\n",
    "    skin_region = cv2.bitwise_and(frame, frame, mask=skin_mask)\n",
    "    return skin_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88de2f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skin_colour(image):\n",
    "    skin= detect_faces_with_skin_region(image)\n",
    "    skin_mask = detect_faces_with_skin_mask(image)\n",
    "    \n",
    "    # Calculate the avg color \n",
    "    skin_pxls = image[skin_mask > 0] # Get only skin pixels\n",
    "    if len(skin_pxls) > 0:\n",
    "        avg_colour = np.mean(skin_pxls, axis = 0)\n",
    "    else:\n",
    "        avg_colour = [0,0,0]  #Default if no skin is detected\n",
    "    return avg_colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08388bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_skin_colour(image, skin_colour):\n",
    "    colour = (int(skin_colour[0]), int(skin_colour[1]), int(skin_colour[2]))\n",
    "    cv2.putText(image, \"Skin Colour: \", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    cv2.rectangle(image, (150, 10), (180, 40), colour, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6778c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(colour, factor = 1.675):\n",
    "    return tuple(min(int(c * factor), 255) for c in colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2810599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_colour(image):\n",
    "    avg_colour = get_skin_colour(image)\n",
    "    img = increase_brightness(avg_colour)\n",
    "    img = draw_skin_colour(image, img)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b704f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_skin_based_roi(frame):\n",
    "    # Generate the skin mask\n",
    "    skin_mask = detect_faces_with_skin_mask(frame)\n",
    "\n",
    "    # Find contours in the skin mask\n",
    "    contours, _ = cv2.findContours(\n",
    "        skin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # If contours are found, proceed to find the largest skin region\n",
    "    if contours:\n",
    "        # Find the largest contour by area, which is likely the main skin region\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Get the bounding box of the largest contour\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # Define the ROI based on the bounding box of the largest contour\n",
    "        roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "        return roi, (x, y, w, h)  # Return the ROI and bounding box coordinates\n",
    "    else:\n",
    "        print(\"No significant skin-colored region detected.\")\n",
    "        return None, None  # Return None if no skin region is found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31fa4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    img = resize(image)\n",
    "    #img = BiLateralFitlerDenoise(img)\n",
    "    #img = enhanceContrast(img)\n",
    "    img = unsharpMask(img)\n",
    "    img = unsharpMask(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7020424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_hair_colour(img, face_roi):\n",
    "    # Get the ROI of the face\n",
    "    x, y, w, h = face_roi\n",
    "    hair_roi = img[max(0, y - h // 2):y, x:x + w]\n",
    "    \n",
    "    if hair_roi.size == 0:\n",
    "        print(\"Error, No har region detected\")\n",
    "    \n",
    "    # Convert color to HSV\n",
    "    hsv = cv2.cvtColor(hair_roi, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Mask out non-hair color\n",
    "    min_hsv = np.array([0, 10, 50])\n",
    "    max_hsv = np.array([180, 255, 255])\n",
    "    hair_mask = cv2.inRange(hsv, min_hsv, max_hsv)\n",
    "    \n",
    "    # Get the non zero pixel for clustering\n",
    "    hair_pxls = hsv[hair_mask > 0]\n",
    "    if hair_pxls.size == 0:\n",
    "        print(\"Error No hair pixels detected\")\n",
    "        \n",
    "    # Use K-means clustering to find the dominant colour\n",
    "    kmeans = KMeans(n_clusters=1, random_state=0)\n",
    "    kmeans.fit(hair_pxls)\n",
    "    hsv_colour = kmeans.cluster_centers_[0]\n",
    "    \n",
    "    # Convert hsv_colour back to RGB\n",
    "    bgr_colour = cv2.cvtColor(np.uint8([[hsv_colour]]), cv2.COLOR_HSV2BGR)[0][0]\n",
    "    \n",
    "    # Make a list to store the BGR\n",
    "    BGR_List =[]\n",
    "    \n",
    "    # For loop through the bgr_colour values\n",
    "    for c in bgr_colour:\n",
    "        \n",
    "        # Append them to the list\n",
    "        BGR_List.append(int(c))\n",
    "        \n",
    "    # Convert list to Tuple\n",
    "    BGR_Tuple = tuple(BGR_List)\n",
    "    \n",
    "    # Return the Tuple containing the primary colour\n",
    "    return BGR_Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c2014e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_hair_colour(img, face_roi):\n",
    "    # Call the detect hair colour\n",
    "    hair_colour = detect_hair_colour(img, face_roi)\n",
    "    msg = f\"Hair Colour is (BGR): {hair_colour}\"\n",
    "    eg.msgbox(msg, title=\"Hair Colour Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cee17a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_hair_colour(bgr_colour):\n",
    "    b, g, r = bgr_colour\n",
    "    # Threshold for basic hair colours\n",
    "    if b <50 and g < 50 and r < 50:\n",
    "        return \"Black\"\n",
    "    elif r > 150 and g < 100 and b < 100:\n",
    "        return \"Red\"\n",
    "    elif r > 200 and g > 180 and b > 130:\n",
    "        return \"Blonde\"\n",
    "    elif r > 100 and g > 70 and b > 50:\n",
    "        return \"Brunette\"\n",
    "    else:\n",
    "        return \"Unknown Hair Colour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ecd272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectEyes(roi):\n",
    "    roi = roi[roi.shape[1] //3:roi.shape[1]//3*2, roi.shape[1] //3:roi.shape[1]//3*2]\n",
    "    cv2.imshow(\"Roi\", roi)\n",
    "    gray_roi = cv2.cvtColor(roi ,cv2.COLOR_BGR2GRAY)\n",
    "    #enhance contrast \n",
    "    enhanced_roi = enhanceContrast(gray_roi)\n",
    "\n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(enhanced_roi, 100, 200)\n",
    " \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filter contours to locate eyes (by size, shape, position)\n",
    "    eye_contours = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = w / h\n",
    "        if 0.8 < aspect_ratio < 2.5 and y < gray_roi.shape[0] // 2 and y > gray_roi.shape[0] // 10 and w >10 and h > 10:\n",
    "            eye_contours.append((x, y, w, h))\n",
    "\n",
    "    eye_regions = []\n",
    "    for (x, y, w, h) in eye_contours:\n",
    "        eye_regions.append(roi[y:y+h, x:x+w])\n",
    "\n",
    "    for eye in eye_regions:\n",
    "        # Convert to HSV for better color analysis\n",
    "        hsv_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2HSV)\n",
    "       \n",
    "        # Flatten the image and get the dominant color\n",
    "        hsv_values = hsv_eye.reshape((-1, 3))\n",
    "\n",
    "        if len(hsv_values) < 2:  # Check if there are enough pixels for clustering\n",
    "            print(\"Not enough data points for clustering.\")\n",
    "            dominant_color = None\n",
    "        else:\n",
    "            # K-means clustering to find the dominant color\n",
    "            n_clusters = min(2, len(hsv_values))\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            kmeans.fit(hsv_values)\n",
    "\n",
    "            # check on cluster centers\n",
    "            if len(kmeans.cluster_centers_) > 1:\n",
    "                dominant_color = kmeans.cluster_centers_[np.bincount(kmeans.labels_).argmax()]\n",
    "            else:\n",
    "                dominant_color = kmeans.cluster_centers_[0]  # Only one cluster\n",
    "\n",
    "            # Get the color name or visualize it\n",
    "            print(f\"Dominant eye color in HSV: {dominant_color}\")\n",
    "\n",
    "    for (x, y, w, h) in eye_contours:\n",
    "        cv2.rectangle(roi, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # Return ROI with rectangles drawn around eyes\n",
    "    return roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f06442e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting the program.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    frame = None\n",
    "    while True:\n",
    "        # Prompt user to choose between image or video upload or exit\n",
    "        choices = [\"1. Image Upload\", \"2. Video Upload\", \"3. Take Photo\", \"4. Show Colour\", \"5. Detect Hair Colour\", \"6. Detect Eyes\", \"7. Exit\"]\n",
    "        user_choice = eg.choicebox(\"Choose an option:\", \"Upload Choice\", choices)\n",
    "\n",
    "        if user_choice == \"1. Image Upload\":\n",
    "            # Handle image upload\n",
    "            file_path = image_file_explore()\n",
    "            if not file_path:\n",
    "                continue  # Return to the main menu\n",
    "\n",
    "            # Load and process the image\n",
    "            frame = cv2.imread(file_path)\n",
    "            frame = preprocessing(frame)\n",
    "            if frame is None:\n",
    "                eg.msgbox(\"Failed to load the image file.\", \"Error\")\n",
    "                continue  # Return to the main menu\n",
    "\n",
    "\n",
    "        elif user_choice == \"2. Video Upload\":\n",
    "            # Handle video upload\n",
    "            file_path = video_file_explore()\n",
    "            if not file_path:\n",
    "                continue  # Return to the main menu\n",
    "\n",
    "            # Open the video file\n",
    "            cap = cv2.VideoCapture(file_path)\n",
    "\n",
    "            # Retrieve the frame rate of the video to set the playback speed\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            delay = int(1000 / fps) if fps > 0 else 33  # Default to ~30 fps if FPS info is unavailable\n",
    "\n",
    "            while True:  # Outer loop for continuous replay\n",
    "                # Reset video to the beginning\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "                while cap.isOpened():\n",
    "                    # Read each frame from the video\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        print(\"Reached end of video.\")\n",
    "                        break\n",
    "                    frame = preprocessing(frame)\n",
    "\n",
    "                    # Perform Skin Mask Detection\n",
    "                    mask = detect_faces_with_skin_mask(frame)\n",
    "                    cv2.imshow('Skin Color Mask', mask)\n",
    "\n",
    "                    # Perform Skin Region Detection\n",
    "                    skin = detect_faces_with_skin_region(frame)\n",
    "                    cv2.imshow('Skin Color Region', skin)\n",
    "\n",
    "\n",
    "                    # Display dynamically calculated Skin-based ROI\n",
    "                    skin_roi, bound_box = capture_skin_based_roi(frame)\n",
    "                    if skin_roi is not None:\n",
    "                        cv2.imshow(\"Skin-based ROI\", skin_roi)\n",
    "                        # Draw bounding box on the original frame\n",
    "                        x, y, w, h = bound_box\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.imshow(\"Original Image with ROI\", frame)\n",
    "\n",
    "                    # Exit the display loop on pressing 'q'\n",
    "                    if cv2.waitKey(delay) & 0xFF in [ord('q'), ord('Q')]:\n",
    "                        break  # Exit the video playback loop\n",
    "\n",
    "                # Ask the user if they want to replay the video\n",
    "                replay_choice = eg.ynbox(\"Do you want to replay the video?\", \"Replay\", [\"Yes\", \"No\"])\n",
    "                if not replay_choice:\n",
    "                    cap.release()\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break  # Exit the outer replay loop\n",
    "\n",
    "        elif user_choice == \"3. Take Photo\":\n",
    "            frame = capture_image()\n",
    "            frame = preprocessing(frame)\n",
    "            \n",
    "            if frame is None:\n",
    "                eg.msgbox(\"Failed to load the image file.\", \"Error\")\n",
    "                continue  # Return to the main menu\n",
    "\n",
    "\n",
    "        elif user_choice == \"4. Show Colour\":\n",
    "            frame = capture_image()\n",
    "            frame = preprocessing(frame)\n",
    "            frame2 = skin_colour(frame)\n",
    "            \n",
    "            cv2.imshow(\"Skin Colour\", frame2)\n",
    "\n",
    "            # Wait for user input to close windows\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        elif user_choice == \"5. Detect Hair Colour\":\n",
    "            if frame is None:\n",
    "                eg.msgbox(\"No image available. Please upload or capture an image\")\n",
    "                continue\n",
    "            \n",
    "            # Perform hair colour detection\n",
    "            skin_roi, bound_box = capture_skin_based_roi(frame)\n",
    "            if skin_roi is not None:\n",
    "                hair_colour_bgr = detect_hair_colour(frame, bound_box)\n",
    "                colour_name = classify_hair_colour(hair_colour_bgr)\n",
    "                eg.msgbox(f\"Hair Colour: {colour_name}\",\"Hair Colour Detected\")\n",
    "            else:\n",
    "                eg.msgbox(\"No hair region detected\")\n",
    "            \n",
    "        \n",
    "        elif user_choice == \"6. Detect Eyes\":\n",
    "            if frame is None:\n",
    "                eg.msgbox(\"No image available. Please upload or capture an image\")\n",
    "                continue\n",
    "            \n",
    "            skin_roi, bound_box = capture_skin_based_roi(frame)\n",
    "            if skin_roi is not None:\n",
    "                \"\"\"\n",
    "                CODE GOES HERE!!!!!!!!!!!!\n",
    "                \"\"\"\n",
    "            else:\n",
    "                eg.msgbox(\"No eyes detected\")\n",
    "            \n",
    "        elif user_choice == \"7. Exit\":\n",
    "            # Exit the program\n",
    "            print(\"Exiting the program.\")\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            eg.msgbox(\"Please make a valid selection.\", \"Error\")\n",
    "            continue  # Continue prompting if no valid choice is selected\n",
    "\n",
    "    # Close any remaining windows and release resources\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5fd62",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120f95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
